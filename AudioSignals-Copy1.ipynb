{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 5 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"./data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(mp3_tracks):\n",
    "    for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "        convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing(mp3_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx, audio in enumerate(tracks):\\n    if idx >= 1:\\n        break\\n    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\n    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\\n        \\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for idx, audio in enumerate(tracks):\n",
    "    if idx >= 1:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOfPeaks(peaks, times):\n",
    "    timesPeaks = []\n",
    "    \n",
    "    for i in peaks:\n",
    "        timesPeaks.append(times[i])\n",
    "    \n",
    "    return timesPeaks   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_hash_float(value:float):\n",
    "    \n",
    "    value = BitArray(float=value, length=64)\n",
    "    phi = (1 + 5 ** 0.5) / 2\n",
    "    g = int(2 ** 64 /phi)\n",
    "    \n",
    "\n",
    "    value ^= value >> 61\n",
    "    value = int(g * value.float * np.random.random_sample())\n",
    " \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_2(vet):\n",
    "    out = 0\n",
    "    for el in vet:\n",
    "        out ^= el\n",
    "        \n",
    "    out = fibonacci_hash_float(out)\n",
    "        \n",
    "    return int(str(out)[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash(freqs, times, threshold = None):\n",
    "    old_threshold = threshold\n",
    "    picks = []\n",
    "    out = []\n",
    "    f = 0\n",
    "    \n",
    "    for i in range(0,threshold):\n",
    "        picks = []\n",
    "        for fr, tm in zip(freqs,times):\n",
    "            picks.append(fibonacci_hash_float(fr) ^ fibonacci_hash_float(tm))\n",
    "        \n",
    "        out.append(np.min(picks))\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signatureMatrix(songs):\n",
    "    sig_matrix = []\n",
    "    for freq, tm in songs:\n",
    "        sig_matrix.append(minhash(freq,tm, 5))\n",
    "        \n",
    "    return np.array(sig_matrix).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(sig_matrix, b=2):\n",
    "\n",
    "    band_numb = sig_matrix.shape[0]//b\n",
    "    bucket_matrix = []\n",
    "\n",
    "    for i in range(0,band_numb):\n",
    "\n",
    "        band = m[b*i:b*(i+1)]\n",
    "        \n",
    "        bucket_row = defaultdict(lambda: 0)\n",
    "        \n",
    "        for j in range(band.shape[1]):\n",
    "            \n",
    "            bucket_row[hash_2(band[:,j])] += 1\n",
    "\n",
    "        bucket_matrix.append(bucket_row.values())\n",
    "\n",
    "\n",
    "    return np.array(bucket_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_song(song):\n",
    "    hashtable = pd.read_csv(\"./data/hashtable.csv\", index_col=\"hashid\")\n",
    "    \n",
    "    #get the frequencies and time of picks \n",
    "    track, sr, onset_env, peaks = load_audio_picks(song, DURATION, HOP_SIZE)\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "    timesPeaks = timeOfPeaks(peaks, times)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "    \n",
    "    #do the minhash of the song\n",
    "    h = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\n",
    "    \n",
    "    return (hashtable.loc[h][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hashtable():\n",
    "    hashtable = []\n",
    "    names = []\n",
    "    data = pd.DataFrame()\n",
    "    for idx, audio in tqdm(enumerate(tracks), total = N_TRACKS):\n",
    "        names.append(audio.name)\n",
    "        track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "        timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "        timesPeaks = timeOfPeaks(peaks, timess)\n",
    "        freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "\n",
    "        hashtable.append(minhash(freqsP, timesPeaks, THRESHOLD, DURATION))\n",
    "\n",
    "    data['hashid'] = hashtable\n",
    "    data['name'] = names\n",
    "    data.to_csv('data/hashtable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_hashtable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"./data/hashtable.csv\", index_col=\"hashid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with some test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca0f89867d847b0b7833bd0b5312950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "songs = []\n",
    "for idx, audio in tqdm(enumerate(tracks), total = N_TRACKS):\n",
    "    if(idx > 4):\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    timesPeaks = timeOfPeaks(peaks, timess)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "    songs.append((freqsP, timesPeaks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_m = make_signatureMatrix(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2599823476760257536, 5235882738895912960, 1519980343989952848,\n",
       "          14138150187448320, 7810486529529361408],\n",
       "       [4770035240315681280,  829978137479610368, 2290948224215203840,\n",
       "        2340465178254475264, 1929932249329175040],\n",
       "       [2277858609715068928, 1029899941942870016,  697980105098465280,\n",
       "         474210908033249280,  225901381859167232],\n",
       "       [3099639594430160896,  180005304757567488, 5722511343032594432,\n",
       "        1124642358261370880, 2470612548683230208],\n",
       "       [1642892077528174592,  350410050667245568, 4470789329091936256,\n",
       "        3820825539325075456, 3023336120105865216]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the fisrt query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"audio = 'data/queries/track3.wav'\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"audio = 'data/queries/track3.wav'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the hashmin of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\ntimess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\\ntimesPeaks = timeOfPeaks(peaks, timess)\\nfreqsP = [onset_env[i] for i in peaks]\\n    \\nh = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\\nh'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, timess)\n",
    "freqsP = [onset_env[i] for i in peaks]\n",
    "    \n",
    "h = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\n",
    "h\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see if it match something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guess_song(audio)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"guess_song(audio)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_folder2 = Path(\"./data/queries/\")\\nquery_tracks = data_folder2.glob(\"./*.wav\")\\nget = 0\\nmiss = 0\\nfor query in query_tracks:\\n    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\\n    try:\\n        print(guess_song(query))\\n        get += 1\\n    except KeyError:\\n        print(\"Not matched!\")\\n        miss += 1\\n    print(\"\\n===========================================\\n\")\\n    \\nprint(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_folder2 = Path(\"./data/queries/\")\n",
    "query_tracks = data_folder2.glob(\"./*.wav\")\n",
    "get = 0\n",
    "miss = 0\n",
    "for query in query_tracks:\n",
    "    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\n",
    "    try:\n",
    "        print(guess_song(query))\n",
    "        get += 1\n",
    "    except KeyError:\n",
    "        print(\"Not matched!\")\n",
    "        miss += 1\n",
    "    print(\"\\n===========================================\\n\")\n",
    "    \n",
    "print(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab321cb1acdda0c363d7de36f5defdacb4b1bdc03056ebbf5164ad5dbb0ce6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
