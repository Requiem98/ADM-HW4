{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 5 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"./data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(mp3_tracks):\n",
    "    for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "        convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing(mp3_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx, audio in enumerate(tracks):\\n    if idx >= 1:\\n        break\\n    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\n    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\\n        \\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for idx, audio in enumerate(tracks):\n",
    "    if idx >= 1:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import pandas as pd\n",
    "from collections import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOfPeaks(peaks, times):\n",
    "    timesPeaks = []\n",
    "    \n",
    "    for i in peaks:\n",
    "        timesPeaks.append(times[i])\n",
    "    \n",
    "    return timesPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_hash_float(value:float, rand = False, hash_size = 15):\n",
    "\n",
    "    value = BitArray(float=value, length=64)\n",
    "    phi = (1 + 5 ** 0.5) / 2\n",
    "    g = int(2 ** 64 /phi)\n",
    "\n",
    "\n",
    "    value ^= value >> 61\n",
    "\n",
    "    if(rand):\n",
    "        value = int(g * value.float * np.random.random_sample(1))\n",
    "    else:\n",
    "        value = int(g * value.float)\n",
    "\n",
    "    return int(str(value)[0:hash_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self):\n",
    "        self.hash_table = dict()\n",
    "        \n",
    "    def generate_hash(self, inp_vector):\n",
    "        hashVal = \"\".join(inp_vector)\n",
    "        return hashVal\n",
    "            \n",
    "    def setitem(self, vec, label):\n",
    "        val = self.generate_hash(vec)\n",
    "        self.hash_table[val] = label\n",
    "        \n",
    "    def getitem(self, inp_vec):\n",
    "        hash_value = self.generate_hash(inp_vec)\n",
    "        return self.hash_table.get(hash_value, [])\n",
    "    \n",
    "    def getTable(self):\n",
    "        return(self.hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, num_tables, threshold, b):\n",
    "        assert num_tables == threshold//b, \"The number of table must be equals to threshold // band\"\n",
    "        self.num_tables = num_tables\n",
    "        self.band = b\n",
    "        self.threshold = threshold\n",
    "        self.hash_tables = list()\n",
    "        for i in range(self.num_tables):\n",
    "            self.hash_tables.append(HashTable())\n",
    "        \n",
    "            \n",
    "    def minhash(self, vec, label):\n",
    "        \n",
    "        out = defaultdict(list)\n",
    "        \n",
    "        for i in range(0,self.threshold):\n",
    "            random.shuffle(vec)\n",
    "            \n",
    "            for idx, num in enumerate(vec):\n",
    "                if(num != 0):\n",
    "                    out[i//self.band].append(str(idx))\n",
    "                    break\n",
    "            \n",
    "\n",
    "        for el, table in zip(out, self.hash_tables):\n",
    "            table.setitem(out[el], label)\n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        print(\"Numero di tabelle: \" + str(self.num_tables))\n",
    "        print(\"Elementi per tabella: \" + str(len(self.hash_tables[0].hash_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fingerprints(audio, duration, hop):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "    timesPeaks = timeOfPeaks(peaks, times)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "    fingerprints = []\n",
    "    sec = hop\n",
    "    time=0\n",
    "    count=0\n",
    "    while(sec <= duration):\n",
    "\n",
    "        idx = 0\n",
    "        hashVal = 0\n",
    "        count += 1\n",
    "\n",
    "        while(time <=sec):\n",
    "            \n",
    "            if(timesPeaks[idx] < sec and timesPeaks[idx] > time):\n",
    "                hashVal ^= fibonacci_hash_float(freqsP[idx]) ^ hashVal\n",
    "                \n",
    "\n",
    "            time = timesPeaks[idx]\n",
    "           \n",
    "            if(idx+1 < len(freqsP)):\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        fingerprints.append(hashVal)\n",
    "        \n",
    "        sec += hop\n",
    "        \n",
    " \n",
    "        \n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = make_fingerprints(\"./data/mp3s-32k/green_day/Dookie/01-Burnout.wav\", 30, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creao fingerprints da 1 secondo della canzone.\n",
    "\n",
    "come creo i backet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with some test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_LSH(song = \"NA\"):\n",
    "    \n",
    "    lsh = LSH(50, 50, 1)\n",
    "    \n",
    "    if(song == \"NA\"):\n",
    "        \n",
    "        for idx, audio in tqdm(enumerate(tracks), total = N_TRACKS):\n",
    "\n",
    "            fingerprint = make_fingerprints(audio, DURATION, 0.1)\n",
    "\n",
    "            lsh.minhash(fingerprint, audio.name)\n",
    "    else:\n",
    "        fingerprint = make_fingerprints(song, DURATION, 0.1)\n",
    "        \n",
    "        lsh.minhash(fingerprint, song)\n",
    "        \n",
    "    return lsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForCollision(lsh, lsh_q):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    dic = defaultdict(int)\n",
    "    for table, tableq in zip(lsh.hash_tables, lsh_q.hash_tables):\n",
    "        \n",
    "        match = table.hash_table.get([*tableq.hash_table.keys()][0], \"NA\")\n",
    "        if(match != 'NA'):\n",
    "            dic[match] += 1\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'10-Waiting.wav': 6,\n",
       "             '06-Misery.wav': 5,\n",
       "             '04-Fashion_Victim.wav': 1,\n",
       "             '03-Welcome_To_Paradise.wav': 1,\n",
       "             '07-Deadbeat_Holiday.wav': 5,\n",
       "             '16-My_Generation.wav': 1,\n",
       "             '09-Uptight.wav': 1,\n",
       "             '12-Macy_s_Day_Parade.wav': 3,\n",
       "             '05-Castaway.wav': 2,\n",
       "             '02-Blood_Sex_And_Booze.wav': 2,\n",
       "             '09-Jackass.wav': 3,\n",
       "             '11-Minority.wav': 2,\n",
       "             '11-Who_Wrote_Holden_Caulfield_.wav': 1,\n",
       "             '08-She_s_a_Rebel.wav': 1,\n",
       "             '15-Strangeland.wav': 3,\n",
       "             '03-Church_On_Sunday.wav': 1,\n",
       "             '01-Warning.wav': 2,\n",
       "             '14-Walking_Contradiction.wav': 1,\n",
       "             '06-Say_Goodbye.wav': 1,\n",
       "             '08-80.wav': 1,\n",
       "             '08-Hold_On.wav': 1,\n",
       "             '07-Give_Me_Novacaine.wav': 1,\n",
       "             '18-Prosthetic_Head.wav': 1,\n",
       "             '11-Jinx.wav': 1,\n",
       "             '06-Dominated_Love_Slave.wav': 1,\n",
       "             '09-Stuart_And_The_Ave_.wav': 2})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lsh = populate_LSH()\n",
    "\n",
    "lsh_q = populate_LSH(\"./data/queries/track1.wav\")\n",
    "out = searchForCollision(lsh, lsh_q)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(lsh, \"./data/lsh_50_50_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '02-Blood_Sex_And_Booze.wav',\n",
       " '11': '05-Welcome_to_Paradise.wav',\n",
       " '2': '09-Jackass.wav',\n",
       " '0': '04-Fashion_Victim.wav',\n",
       " '6': '05-Private_Ale.wav',\n",
       " '5': '10-Waiting.wav',\n",
       " '3': '06-Misery.wav',\n",
       " '8': '08-She_s_a_Rebel.wav',\n",
       " '32': '01-2_2_5_The_Lukewarm_.wav',\n",
       " '10': '07-Deadbeat_Holiday.wav',\n",
       " '4': '10-No_One_Knows.wav',\n",
       " '7': '13-Walking_Alone.wav',\n",
       " '9': '08-Platypus_I_Hate_You_.wav',\n",
       " '15': '07-Give_Me_Novacaine.wav',\n",
       " '22': '06-Tomorrow.wav',\n",
       " '18': '14-F_O_D_-All_By_Myself.wav',\n",
       " '14': '13-In_the_End.wav',\n",
       " '26': '06-Mint_Car.wav',\n",
       " '17': '12-Westbound_Sign.wav',\n",
       " '24': '06-Only_over_You.wav',\n",
       " '16': '02-Hitchin_A_Ride.wav',\n",
       " '12': '03-Satellite.wav',\n",
       " '21': '04-Sometimes.wav',\n",
       " '13': '02-When_The_World_Ends.wav',\n",
       " '19': '12-Love_Is_Blindness.wav',\n",
       " '28': '01-In_the_Light.wav',\n",
       " '36': '18-Gold_Dust.wav',\n",
       " '38': '09-Frozen.wav',\n",
       " '20': '06-The_Refugee.wav',\n",
       " '42': '10-Ultra_Violet_Light_My_Way_.wav',\n",
       " '37': '01-Dreamgirl.wav',\n",
       " '27': '01-2000_Light_Years_Away.wav'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.hash_tables[24].hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9': './data/queries/track1.wav'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_q.hash_tables[0].hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': '10-Last_Ride_In.wav',\n",
       " '9': '05-Castaway.wav',\n",
       " '11': '04-Fashion_Victim.wav',\n",
       " '0': '10-Waiting.wav',\n",
       " '10': '13-Steady_As_We_Go.wav',\n",
       " '3': '02-Blood_Sex_And_Booze.wav',\n",
       " '8': '11-Jinx.wav',\n",
       " '1': '06-Misery.wav',\n",
       " '12': '06-Red_Hill_Mining_Town.wav',\n",
       " '19': '11-Spoon.wav',\n",
       " '2': '08-Hold_On.wav',\n",
       " '6': '01-2000_Light_Years_Away.wav',\n",
       " '7': '07-Deadbeat_Holiday.wav',\n",
       " '14': '14-Walking_Contradiction.wav',\n",
       " '17': '03-Spaced.wav',\n",
       " '4': '12-Macy_s_Day_Parade.wav',\n",
       " '16': '04-The_Unforgiven_II.wav',\n",
       " '15': '11-Who_Wrote_Holden_Caulfield_.wav',\n",
       " '23': '02-Can_t_Go_Back.wav',\n",
       " '26': '05-The_Max.wav',\n",
       " '29': '05-Darling_Nikki.wav',\n",
       " '13': '12-Haushinka.wav',\n",
       " '21': '05-Institution_Green.wav',\n",
       " '43': '04-Sacred.wav',\n",
       " '20': '13-Mer_Girl.wav',\n",
       " '18': '07-Dear_Jessie.wav'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.hash_tables[0].hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash(vec, label):\n",
    "\n",
    "    out = defaultdict(list)\n",
    "\n",
    "    for i in range(0,40):\n",
    "        random.shuffle(vec)\n",
    "\n",
    "        for idx, num in enumerate(vec):\n",
    "            if(num != 0):\n",
    "                out[i//2].append(idx)\n",
    "                break\n",
    "\n",
    "\n",
    "    \"\"\"for el, table in zip(out, self.hash_tables):\n",
    "        table.setitem(out[el], label)\"\"\"\n",
    "    return out, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioq = \"./data/queries/track1.wav\"\n",
    "audio = \"./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the fisrt query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"audio = 'data/queries/track3.wav'\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"audio = 'data/queries/track3.wav'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the hashmin of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\ntimess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\\ntimesPeaks = timeOfPeaks(peaks, timess)\\nfreqsP = [onset_env[i] for i in peaks]\\n    \\nh = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\\nh'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, timess)\n",
    "freqsP = [onset_env[i] for i in peaks]\n",
    "    \n",
    "h = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\n",
    "h\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see if it match something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guess_song(audio)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"guess_song(audio)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_folder2 = Path(\"./data/queries/\")\\nquery_tracks = data_folder2.glob(\"./*.wav\")\\nget = 0\\nmiss = 0\\nfor query in query_tracks:\\n    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\\n    try:\\n        print(guess_song(query))\\n        get += 1\\n    except KeyError:\\n        print(\"Not matched!\")\\n        miss += 1\\n    print(\"\\n===========================================\\n\")\\n    \\nprint(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_folder2 = Path(\"./data/queries/\")\n",
    "query_tracks = data_folder2.glob(\"./*.wav\")\n",
    "get = 0\n",
    "miss = 0\n",
    "for query in query_tracks:\n",
    "    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\n",
    "    try:\n",
    "        print(guess_song(query))\n",
    "        get += 1\n",
    "    except KeyError:\n",
    "        print(\"Not matched!\")\n",
    "        miss += 1\n",
    "    print(\"\\n===========================================\\n\")\n",
    "    \n",
    "print(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab321cb1acdda0c363d7de36f5defdacb4b1bdc03056ebbf5164ad5dbb0ce6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
