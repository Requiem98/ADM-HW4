{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 5 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"./data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(mp3_tracks):\n",
    "    for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "        convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing(mp3_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx, audio in enumerate(tracks):\\n    if idx >= 1:\\n        break\\n    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\n    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\\n        \\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for idx, audio in enumerate(tracks):\n",
    "    if idx >= 1:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import pandas as pd\n",
    "from collections import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOfPeaks(peaks, times):\n",
    "    timesPeaks = []\n",
    "    \n",
    "    for i in peaks:\n",
    "        timesPeaks.append(times[i])\n",
    "    \n",
    "    return timesPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_hash_float(value:float, rand = False, hash_size = 15):\n",
    "\n",
    "    value = BitArray(float=value, length=64)\n",
    "    phi = (1 + 5 ** 0.5) / 2\n",
    "    g = int(2 ** 64 /phi)\n",
    "\n",
    "\n",
    "    value ^= value >> 61\n",
    "\n",
    "    if(rand):\n",
    "        value = int(g * value.float * np.random.random_sample(1))\n",
    "    else:\n",
    "        value = int(g * value.float)\n",
    "\n",
    "    return int(str(value)[0:hash_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, hash_size):\n",
    "        self.hash_size = hash_size\n",
    "        self.hash_table = dict()\n",
    "        \n",
    "    def generate_hash(self, inp_vector):\n",
    "        hashVal = 0\n",
    "        for val in inp_vector:\n",
    "            hashVal ^= fibonacci_hash_float(val, hash_size=self.hash_size) ^ hashVal\n",
    "        return hashVal\n",
    "            \n",
    "    def setitem(self, vec, label):\n",
    "        val = self.generate_hash(vec)\n",
    "        self.hash_table[val] = label\n",
    "        \n",
    "    def getitem(self, inp_vec):\n",
    "        hash_value = self.generate_hash(inp_vec)\n",
    "        return self.hash_table.get(hash_value, [])\n",
    "    \n",
    "    def getTable(self):\n",
    "        return(self.hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, num_tables, hash_size, threshold, b):\n",
    "        assert num_tables == threshold//b, \"The number of table must be equals to threshold // band\"\n",
    "        self.num_tables = num_tables\n",
    "        self.band = b\n",
    "        self.hash_size = hash_size\n",
    "        self.threshold = threshold\n",
    "        self.hash_tables = list()\n",
    "        for i in range(self.num_tables):\n",
    "            self.hash_tables.append(HashTable(self.hash_size))\n",
    "        \n",
    "            \n",
    "    def minhash(self, vec, label):\n",
    "        \n",
    "        out = defaultdict(list)\n",
    "        \n",
    "        for i in range(0,self.threshold):\n",
    "            random.shuffle(vec)\n",
    "            out[i//self.band].append(vec[0])\n",
    "            \n",
    "\n",
    "        for el, table in zip(out, self.hash_tables):\n",
    "            table.setitem(out[el], label)\n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        print(\"Numero di tabelle: \" + str(self.num_tables))\n",
    "        print(\"Elementi per tabella: \" + str(len(self.hash_tables[0].hash_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fingerprints(audio, duration, hop):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "    timesPeaks = timeOfPeaks(peaks, times)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "    fingerprints = []\n",
    "    sec = hop\n",
    "    time=0\n",
    "    count=0\n",
    "    while(sec <= duration):\n",
    "\n",
    "        idx = 0\n",
    "        hashVal = 0\n",
    "        count += 1\n",
    "\n",
    "        while(time <=sec):\n",
    "            \n",
    "            if(timesPeaks[idx] < sec and timesPeaks[idx] > time):\n",
    "                hashVal ^= fibonacci_hash_float(freqsP[idx]) ^ hashVal\n",
    "                \n",
    "\n",
    "            time = timesPeaks[idx]\n",
    "           \n",
    "            if(idx+1 < len(freqsP)):\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        fingerprints.append(hashVal)\n",
    "        \n",
    "        sec += hop\n",
    "        \n",
    " \n",
    "        \n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_fingerprints(\"./data/mp3s-32k/green_day/Dookie/01-Burnout.wav\", 30, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "track, sr, onset_env, peaks = load_audio_picks(\"./data/mp3s-32k/green_day/Dookie/08-She.wav\", DURATION, HOP_SIZE)\n",
    "times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, times)\n",
    "freqsP = [onset_env[i] for i in peaks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creao fingerprints da 1 secondo della canzone.\n",
    "\n",
    "come creo i backet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = HashTable(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.setitem([4.0,4.0,4.0], \"Test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4560: 'Test1'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.getTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010000000000021103"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 - (4 -0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with some test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f2120eb70641769c9a4fab4d72072f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsh = LSH(20, 15, 40, 2)\n",
    "for idx, audio in tqdm(enumerate(tracks), total = N_TRACKS):\n",
    "    \n",
    "    fingerprint = make_fingerprints(audio, DURATION, 0.1)\n",
    "    \n",
    "    lsh.minhash(fingerprint, audio.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di tabelle: 20\n",
      "Elementi per tabella: 1386\n"
     ]
    }
   ],
   "source": [
    "lsh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_q = LSH(40,15,200,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = 'data/mp3s-32k/aerosmith/Aerosmith/08-Walking_the_Dog.wav'\n",
    "track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, timess)\n",
    "freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "lsh_q.minhash(freqsP, timesPeaks, \"03-Dream_On.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121746900990048"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*lsh_q.hash_tables[0].hash_table.keys()][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for table, tableq in zip(lsh.hash_tables, lsh_q.hash_tables):\n",
    "    if(table.hash_table.get([*tableq.hash_table.keys()][0], \"NA\") != \"NA\"):\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioq = \"./data/queries/track1.wav\"\n",
    "audio = \"./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav\"\n",
    "lsh_q = LSH(20,15, 40, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, timess)\n",
    "freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "lsh.minhash(freqsP, timesPeaks, audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "track, sr, onset_env, peaks = load_audio_picks(audioq, 10, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaksq = timeOfPeaks(peaks, timess)\n",
    "freqsPq = [onset_env[i] for i in peaks]\n",
    "\n",
    "lsh_q.minhash(freqsPq, timesPeaksq, audioq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{451662649439009: './data/queries/track1.wav'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_q.hash_tables[3].hash_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the fisrt query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"audio = 'data/queries/track3.wav'\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"audio = 'data/queries/track3.wav'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the hashmin of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\ntimess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\\ntimesPeaks = timeOfPeaks(peaks, timess)\\nfreqsP = [onset_env[i] for i in peaks]\\n    \\nh = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\\nh'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, timess)\n",
    "freqsP = [onset_env[i] for i in peaks]\n",
    "    \n",
    "h = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\n",
    "h\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see if it match something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guess_song(audio)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"guess_song(audio)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_folder2 = Path(\"./data/queries/\")\\nquery_tracks = data_folder2.glob(\"./*.wav\")\\nget = 0\\nmiss = 0\\nfor query in query_tracks:\\n    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\\n    try:\\n        print(guess_song(query))\\n        get += 1\\n    except KeyError:\\n        print(\"Not matched!\")\\n        miss += 1\\n    print(\"\\n===========================================\\n\")\\n    \\nprint(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_folder2 = Path(\"./data/queries/\")\n",
    "query_tracks = data_folder2.glob(\"./*.wav\")\n",
    "get = 0\n",
    "miss = 0\n",
    "for query in query_tracks:\n",
    "    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\n",
    "    try:\n",
    "        print(guess_song(query))\n",
    "        get += 1\n",
    "    except KeyError:\n",
    "        print(\"Not matched!\")\n",
    "        miss += 1\n",
    "    print(\"\\n===========================================\\n\")\n",
    "    \n",
    "print(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab321cb1acdda0c363d7de36f5defdacb4b1bdc03056ebbf5164ad5dbb0ce6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
