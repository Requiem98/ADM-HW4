{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 5 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"./data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(mp3_tracks):\n",
    "    for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "        convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing(mp3_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx, audio in enumerate(tracks):\\n    if idx >= 1:\\n        break\\n    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\\n    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\\n        \\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for idx, audio in enumerate(tracks):\n",
    "    if idx >= 1:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import pandas as pd\n",
    "from collections import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOfPeaks(peaks, times):\n",
    "    timesPeaks = []\n",
    "    \n",
    "    for i in peaks:\n",
    "        timesPeaks.append(times[i])\n",
    "    \n",
    "    return timesPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_hash_float(value:float, rand = False, hash_size = 15):\n",
    "\n",
    "    value = BitArray(float=value, length=64)\n",
    "    phi = (1 + 5 ** 0.5) / 2\n",
    "    g = int(2 ** 64 /phi)\n",
    "\n",
    "\n",
    "    value ^= value >> 61\n",
    "\n",
    "    if(rand):\n",
    "        value = int(g * value.float * np.random.random_sample(1))\n",
    "    else:\n",
    "        value = int(g * value.float)\n",
    "\n",
    "    return int(str(value)[0:hash_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self):\n",
    "        self.hash_table = defaultdict(list)\n",
    "        \n",
    "    def generate_hash(self, inp_vector):\n",
    "        hashVal = \"\".join(inp_vector)\n",
    "        return hashVal\n",
    "            \n",
    "    def setitem(self, vec, label):\n",
    "        val = self.generate_hash(vec)\n",
    "        self.hash_table[val].append(label)\n",
    "        \n",
    "    def getitem(self, inp_vec):\n",
    "        hash_value = self.generate_hash(inp_vec)\n",
    "        return self.hash_table.get(hash_value, [])\n",
    "    \n",
    "    def getTable(self):\n",
    "        return(self.hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, num_tables, threshold, b):\n",
    "        assert num_tables == threshold//b, \"The number of table must be equals to threshold // band\"\n",
    "        self.num_tables = num_tables\n",
    "        self.band = b\n",
    "        self.threshold = threshold\n",
    "        self.hash_tables = list()\n",
    "        for i in range(self.num_tables):\n",
    "            self.hash_tables.append(HashTable())\n",
    "        \n",
    "            \n",
    "    def minhash(self, vec, label):\n",
    "        \n",
    "        out = defaultdict(list)\n",
    "        \n",
    "        for i in range(0,self.threshold):\n",
    "            random.shuffle(vec)\n",
    "    \n",
    "            for idx, num in enumerate(vec):\n",
    "    \n",
    "                if(num != 0):\n",
    "                    \n",
    "                    out[i//self.band].append(str(idx))\n",
    "                    break\n",
    "        \n",
    "\n",
    "        for el, table in zip(out, self.hash_tables):\n",
    "            table.setitem(out[el], label)\n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        print(\"Numero di tabelle: \" + str(self.num_tables))\n",
    "        print(\"Elementi per tabella: \" + str(len(self.hash_tables[0].hash_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fingerprints(audio, duration, hop):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "    timesPeaks = timeOfPeaks(peaks, times)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "\n",
    "    fingerprints = []\n",
    "    sec = hop\n",
    "    time=0\n",
    "    count=0\n",
    "    while(sec <= duration):\n",
    "\n",
    "        idx = 0\n",
    "        hashVal = 0\n",
    "        count += 1\n",
    "\n",
    "        while(time <=sec):\n",
    "            \n",
    "            if(timesPeaks[idx] < sec and timesPeaks[idx] > time):\n",
    "                hashVal ^= fibonacci_hash_float(freqsP[idx]) ^ hashVal\n",
    "                \n",
    "\n",
    "            time = timesPeaks[idx]\n",
    "           \n",
    "            if(idx+1 < len(freqsP)):\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        fingerprints.append(hashVal)\n",
    "        \n",
    "        sec += hop\n",
    "        \n",
    " \n",
    "        \n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = make_fingerprints(\"./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav\", 30, 0.3)\n",
    "fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creao fingerprints da 1 secondo della canzone.\n",
    "\n",
    "come creo i backet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with some test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_LSH(song = \"NA\"):\n",
    "    \n",
    "    lsh = LSH(15, 150, 10)\n",
    "    \n",
    "    if(song == \"NA\"):\n",
    "        \n",
    "        for idx, audio in tqdm(enumerate(tracks), total = N_TRACKS):\n",
    "\n",
    "            fingerprint = make_fingerprints(audio, DURATION, 0.3)\n",
    "\n",
    "            lsh.minhash(fingerprint, audio.name)\n",
    "    else:\n",
    "        fingerprint = make_fingerprints(song, DURATION, 0.3)\n",
    "        \n",
    "        lsh.minhash(fingerprint, song)\n",
    "        \n",
    "    return lsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForCollision(lsh, lsh_q):\n",
    "    match = list()\n",
    "    \n",
    "    for table, tableq in zip(lsh.hash_tables, lsh_q.hash_tables):\n",
    "        \n",
    "        match.extend(table.hash_table.get([*tableq.hash_table.keys()][0], [\"NA\"]))\n",
    "        \n",
    "    match = list(filter(lambda a: a != \"NA\", match))\n",
    "    \n",
    "    prob = Counter(match).most_common(1)[0][1] / len(match)\n",
    "    \n",
    "    return [Counter(match).most_common(1)[0], prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_object(lsh, \"./data/lsh_50_150_3(0.3).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav', 10), 1.0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh = populate_LSH()\n",
    "save_object(lsh, \"./data/lsh_15_150_10(0.3).pkl\")\n",
    "#lsh = read_object(\"./data/lsh_50_150_3(0.3).pkl\")\n",
    "lsh_q = populate_LSH(\"./data/queries/track1.wav\")\n",
    "out = searchForCollision(lsh, lsh_q)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di tabelle: 50\n",
      "Elementi per tabella: 149\n"
     ]
    }
   ],
   "source": [
    "lsh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'110': ['./data/queries/track1.wav']})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_q.hash_tables[0].hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'010': ['./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav']})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.hash_tables[0].hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioq = \"./data/queries/track1.wav\"\n",
    "audio = \"./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the fisrt query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"audio = 'data/queries/track3.wav'\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the hashmin of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "timess = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "timesPeaks = timeOfPeaks(peaks, timess)\n",
    "freqsP = [onset_env[i] for i in peaks]\n",
    "    \n",
    "h = minhash(freqsP, timesPeaks, THRESHOLD, DURATION)\n",
    "h\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see if it match something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"guess_song(audio)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data_folder2 = Path(\"./data/queries/\")\n",
    "query_tracks = data_folder2.glob(\"./*.wav\")\n",
    "get = 0\n",
    "miss = 0\n",
    "for query in query_tracks:\n",
    "    print(\"\\nCurrent query: \" + str(query) + \"\\n\")\n",
    "    try:\n",
    "        print(guess_song(query))\n",
    "        get += 1\n",
    "    except KeyError:\n",
    "        print(\"Not matched!\")\n",
    "        miss += 1\n",
    "    print(\"\\n===========================================\\n\")\n",
    "    \n",
    "print(\"Song matched: \" + str(get) + \"  Song missed: \" + str(miss))\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab321cb1acdda0c363d7de36f5defdacb4b1bdc03056ebbf5164ad5dbb0ce6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
