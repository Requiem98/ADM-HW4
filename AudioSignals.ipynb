{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 5 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"./data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = list(data_folder.glob(\"*/*/*.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio signals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx, audio in enumerate(tracks):\n",
    "    if idx >= 1:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import pandas as pd\n",
    "from collections import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOfPeaks(peaks, times):\n",
    "    timesPeaks = []\n",
    "    \n",
    "    for i in peaks:\n",
    "        timesPeaks.append(times[i])\n",
    "    \n",
    "    return timesPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_hash_float(value:float, rand = False, hash_size = 18):\n",
    "\n",
    "    value = BitArray(float=value, length=64)\n",
    "    phi = (1 + 5 ** 0.5) / 2\n",
    "    g = int(2 ** 64 /phi)\n",
    "\n",
    "\n",
    "    value ^= value >> 61\n",
    "\n",
    "   \n",
    "    value = int(g * value.float)\n",
    "\n",
    "    return int(str(value)[0:hash_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fingerprints(audio, duration, hop = 0):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, duration, HOP_SIZE)\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "    timesPeaks = timeOfPeaks(peaks, times)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "    fingerprints = []\n",
    "    \n",
    "    if(hop != 0):\n",
    "        sec = hop\n",
    "        time=0\n",
    "        count=0\n",
    "        while(sec <= duration):\n",
    "\n",
    "            idx = 0\n",
    "            hashVal = 0\n",
    "            count += 1\n",
    "\n",
    "            while(time <=sec):\n",
    "\n",
    "                if(timesPeaks[idx] < sec and timesPeaks[idx] > time):\n",
    "                    hashVal ^= fibonacci_hash_float(freqsP[idx]) ^ hashVal\n",
    "\n",
    "\n",
    "                time = timesPeaks[idx]\n",
    "\n",
    "                if(idx+1 < len(freqsP)):\n",
    "                    idx += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            fingerprints.append(hashVal)\n",
    "\n",
    "            sec += hop\n",
    "\n",
    "        fingerprints = list(filter(lambda a: a != 0, fingerprints))\n",
    "    \n",
    "    else:\n",
    "        for fr in freqsP:\n",
    "            fingerprints.append(fr)\n",
    "   \n",
    "    return (fingerprints, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_fingerprints(duration, hop = 0): \n",
    "    tempList = list()\n",
    "    with Pool(multiprocessing.cpu_count()) as pool:\n",
    "       \n",
    "         with tqdm(total = 1413) as pbar:\n",
    "            for i, el in enumerate(pool.imap(lambda song: make_fingerprints(song, duration, hop), songs)):\n",
    "                tempList.append(el)\n",
    "                pbar.update()\n",
    "                \n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPeaks(audio, duration):\n",
    "    _, _, _, peaks = load_audio_picks(audio, duration, HOP_SIZE);\n",
    "    \n",
    "    return (peaks, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_peaks(songs, duration):\n",
    "    \n",
    "    peaks_of_songs = []\n",
    "    \n",
    "    with Pool(multiprocessing.cpu_count()) as pool:\n",
    "\n",
    "        with tqdm(total = 1413) as pbar:\n",
    "            for i, el in enumerate(pool.imap(lambda song: getPeaks(song, duration), songs)):\n",
    "                peaks_of_songs.append(el)\n",
    "                pbar.update()\n",
    "                \n",
    "    return peaks_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, copy, struct\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MIN_HASH(object):\n",
    "\n",
    "    def __init__(self, num_perm=128, seed=1, hashfunc=fibonacci_hash_float, vec = [], label = None):\n",
    "\n",
    "        self._mersenne61 = np.int64((1 << 61) - 1)\n",
    "        self._max_hash = np.int64((1 << 32) - 1)\n",
    "        self.seed = seed\n",
    "        self.num_perm = num_perm\n",
    "        self.hashfunc = hashfunc\n",
    "        self.hashvalues = self._init_hashvalues(num_perm)\n",
    "        self.permutations = self._permutations(num_perm)\n",
    "        self.label = label\n",
    "        \n",
    "        if(len(vec)!=0):\n",
    "            self.update(vec, label)\n",
    "            \n",
    "\n",
    "\n",
    "    def _init_hashvalues(self, num_perm):\n",
    "        return np.ones(num_perm, dtype=np.uint64)*self._max_hash\n",
    "\n",
    "    def _permutations(self, num_perm):\n",
    "        # Create parameters for a random bijective permutation function\n",
    "        # that maps a 32-bit hash value to another 32-bit hash value.\n",
    "        # http://en.wikipedia.org/wiki/Universal_hashing\n",
    "        gen = np.random.RandomState(self.seed)\n",
    "        a_b = []\n",
    "        for _ in range(num_perm):\n",
    "            a_b.append((gen.randint(1, self._mersenne61, dtype=\"int64\"), gen.randint(0, self._mersenne61, dtype=\"int64\")))\n",
    "            \n",
    "        return np.array(a_b, dtype=\"int64\").T\n",
    "\n",
    "\n",
    "    def update(self, vec, label):\n",
    "        self.label = label\n",
    "        hashed_values = np.array([self.hashfunc(el) for el in vec], dtype=\"int64\")\n",
    "        a, b = self.permutations\n",
    "        min_hashed_values = []\n",
    "        for i, j in zip(a,b):\n",
    "            min_hashed_values.append((((hashed_values * i)+j)%self._mersenne61))\n",
    "\n",
    "        phv = np.bitwise_and(np.array(min_hashed_values), self._max_hash).T\n",
    "\n",
    "        self.hashvalues = phv.min(axis=0)\n",
    "\n",
    "    def jaccard(self, other):\n",
    "        return float(np.count_nonzero(self.hashvalues==other.hashvalues)) / float(len(self))\n",
    "    \n",
    "    def __len__(self):\n",
    "    \n",
    "        return len(self.hashvalues)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'\\n======= Label =======\\n{self.label}\\n======= Hash Values =======\\n{self.hashvalues}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self):\n",
    "        self.__hash_table = defaultdict(list)\n",
    "        \n",
    "    def _generate_hash(self, inp_vector):\n",
    "        hashVal = 0\n",
    "        for i in inp_vector:\n",
    "            hashVal ^= fibonacci_hash_float(i) ^ hashVal\n",
    "        return hashVal\n",
    "            \n",
    "    def setitem(self, vec, label):\n",
    "        val = self._generate_hash(vec)\n",
    "        self.hash_table[val].append(label)\n",
    "        \n",
    "        \n",
    "    def getitem(self, inp_vec):\n",
    "        hash_value = self.generate_hash(inp_vec)\n",
    "        return self.hash_table.get(hash_value, [])\n",
    "    \n",
    "    @property\n",
    "    def hash_table(self):\n",
    "        return self.__hash_table\n",
    "    \n",
    "    @hash_table.setter\n",
    "    def hash_table(self, value):\n",
    "        self.__hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, minhash_len, num_band):\n",
    "        \n",
    "        assert minhash_len % num_band == 0, \"the choosen number of band does not hold the following assertion: minhash_len % num_band == 0\"\n",
    "        self.minhash_len = minhash_len\n",
    "        self.num_band = num_band\n",
    "        self.hash_tables = list()\n",
    "        self.minhash_dict = dict()\n",
    "        for i in range(self.num_band):\n",
    "            self.hash_tables.append(HashTable())\n",
    "            \n",
    "            \n",
    "    def addMinHash(self, minhash):\n",
    "        self.minhash_dict[minhash.label] = minhash\n",
    "        self._create_store_band(minhash.hashvalues, minhash.label)\n",
    "            \n",
    "    def _create_store_band(self, vec, label):\n",
    "        \n",
    "        row_per_band = self.minhash_len // self.num_band\n",
    "        \n",
    "        subVec = []\n",
    "        \n",
    "        for i in range(0,self.minhash_len, row_per_band):\n",
    "            subVec.append(vec[i:i+row_per_band])\n",
    "        \n",
    "\n",
    "        for band, table in zip(subVec, self.hash_tables):\n",
    "            table.setitem(band, label)\n",
    "            \n",
    "    \n",
    "    def _create_band(self, vec):\n",
    "        \n",
    "        row_per_band = self.minhash_len // self.num_band\n",
    "        \n",
    "        subVec = []\n",
    "        \n",
    "        for i in range(0,self.minhash_len, row_per_band):\n",
    "            subVec.append(vec[i:i+row_per_band])\n",
    "        \n",
    "        return subVec\n",
    "    \n",
    "            \n",
    "    def query(self, minhash_query):\n",
    "        subVec_query = self._create_band(minhash_query.hashvalues)\n",
    "        match = set()\n",
    "        similarities = []\n",
    "        for table, band in zip(self.hash_tables, subVec_query):\n",
    "            \n",
    "            key = 0\n",
    "            for i in band:\n",
    "                key ^= fibonacci_hash_float(i) ^ key\n",
    "                \n",
    "            if(table.hash_table.get(key, \"NA\") != \"NA\"):\n",
    "                match.update(tuple(table.hash_table.get(key)))\n",
    "                \n",
    "        for m in match:\n",
    "            \n",
    "            similarities.append((self.minhash_dict[m].jaccard(minhash_query), m))\n",
    "            \n",
    "            similarities = [ i for i in sorted(similarities, reverse=True)]\n",
    "                \n",
    "        return similarities\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        print(\"Numero di tabelle: \" + str(self.num_tables))\n",
    "        print(\"Elementi per tabella: \" + str(len(self.hash_tables[0].hash_table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the fisrt query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17513a4884a4e819de103c4baadc199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#shinlges = make_all_fingerprints(duration=30)\n",
    "s#ave_object(peaks, \"./data/fingerprints/fings_dur_30_hop_0.plk\")\n",
    "#shinlges = read_object(\"./data/fingerprints/fings_dur_30_hop_0.plk\")\n",
    "minhashes = []\n",
    "\n",
    "for fing, song in shinlges:\n",
    "    m = MIN_HASH(num_perm=30, vec=fing, label=song)\n",
    "    minhashes.append(m)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mq = MIN_HASH(num_perm=30, vec=make_fingerprints(\"./data/queries/track1.wav\", duration=30)[0], label=\"track2\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out = []\n",
    "for h in minhashes:\n",
    "    out.append((h.jaccard(mq), h.label))\n",
    "\n",
    "\n",
    "[ i for i in sorted(out, reverse=True) if i[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = LSH(minhash_len=30, num_band=10)\n",
    "\n",
    "for i in minhashes:\n",
    "    lsh.addMinHash(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, PosixPath('data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav'))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.query(mq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4641588833612779"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 10\n",
    "r = 30 /b\n",
    "\n",
    "t = (1/b)**(1/r)\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab321cb1acdda0c363d7de36f5defdacb4b1bdc03056ebbf5164ad5dbb0ce6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
