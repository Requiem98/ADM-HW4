{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 5 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"./data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = list(data_folder.glob(\"*/*/*.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio signals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx, audio in enumerate(tracks):\n",
    "    if idx >= 1:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import BitArray\n",
    "import pandas as pd\n",
    "from collections import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_object(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeOfPeaks(peaks, times):\n",
    "    timesPeaks = []\n",
    "    \n",
    "    for i in peaks:\n",
    "        timesPeaks.append(times[i])\n",
    "    \n",
    "    return timesPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_hash_float(value:float, rand = False, hash_size = 15):\n",
    "\n",
    "    value = BitArray(float=value, length=64)\n",
    "    phi = (1 + 5 ** 0.5) / 2\n",
    "    g = int(2 ** 64 /phi)\n",
    "\n",
    "\n",
    "    value ^= value >> 61\n",
    "\n",
    "    if(rand):\n",
    "        value = int(g * value.float * np.random.random_sample(1))\n",
    "    else:\n",
    "        value = int(g * value.float)\n",
    "\n",
    "    return int(str(value)[0:hash_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fingerprints(audio, duration, hop = 0):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, duration, HOP_SIZE)\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE)\n",
    "    timesPeaks = timeOfPeaks(peaks, times)\n",
    "    freqsP = [onset_env[i] for i in peaks]\n",
    "    fingerprints = []\n",
    "    \n",
    "    if(hop != 0):\n",
    "        sec = hop\n",
    "        time=0\n",
    "        count=0\n",
    "        while(sec <= duration):\n",
    "\n",
    "            idx = 0\n",
    "            hashVal = 0\n",
    "            count += 1\n",
    "\n",
    "            while(time <=sec):\n",
    "\n",
    "                if(timesPeaks[idx] < sec and timesPeaks[idx] > time):\n",
    "                    hashVal ^= fibonacci_hash_float(freqsP[idx]) ^ hashVal\n",
    "\n",
    "\n",
    "                time = timesPeaks[idx]\n",
    "\n",
    "                if(idx+1 < len(freqsP)):\n",
    "                    idx += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            fingerprints.append(hashVal)\n",
    "\n",
    "            sec += hop\n",
    "\n",
    "        fingerprints = list(filter(lambda a: a != 0, fingerprints))\n",
    "    \n",
    "    else:\n",
    "        for fr in freqsP:\n",
    "            fingerprints.append(fr)\n",
    "   \n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_fingerprints(duration, hop = 0): \n",
    "    tempList = list()\n",
    "    with Pool(multiprocessing.cpu_count()) as pool:\n",
    "       \n",
    "         with tqdm(total = 1413) as pbar:\n",
    "            for i, el in enumerate(pool.imap(lambda song: make_fingerprints(song, duration, hop), songs)):\n",
    "                tempList.append(el)\n",
    "                pbar.update()\n",
    "                \n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPeaks(audio, duration):\n",
    "    _, _, _, peaks = load_audio_picks(audio, duration, HOP_SIZE);\n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_peaks(songs, duration):\n",
    "    \n",
    "    peaks_of_songs = []\n",
    "    \n",
    "    with Pool(multiprocessing.cpu_count()) as pool:\n",
    "\n",
    "        with tqdm(total = 1413) as pbar:\n",
    "            for i, el in enumerate(pool.imap(lambda song: getPeaks(song, duration), songs)):\n",
    "                peaks_of_songs.append(el)\n",
    "                pbar.update()\n",
    "                \n",
    "    return peaks_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, copy, struct\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MinHash(object):\n",
    "\n",
    "    def __init__(self, num_perm=128, seed=1, hashfunc=fibonacci_hash_float):\n",
    "\n",
    "        self._mersenne_prime = np.uint64((1 << 61) - 1)\n",
    "        self._max_hash = np.uint64((1 << 32) - 1)\n",
    "        self.seed = seed\n",
    "        self.num_perm = num_perm\n",
    "        self.hashfunc = hashfunc\n",
    "        self.hashvalues = self._init_hashvalues(num_perm)\n",
    "        self.permutations = self._init_permutations(num_perm)\n",
    "\n",
    "\n",
    "    def _init_hashvalues(self, num_perm):\n",
    "        return np.ones(num_perm, dtype=np.uint64)*self._max_hash\n",
    "\n",
    "    def _init_permutations(self, num_perm):\n",
    "        # Create parameters for a random bijective permutation function\n",
    "        # that maps a 32-bit hash value to another 32-bit hash value.\n",
    "        # http://en.wikipedia.org/wiki/Universal_hashing\n",
    "        gen = np.random.RandomState(self.seed)\n",
    "        return np.array([\n",
    "            (gen.randint(1, self._mersenne_prime, dtype=np.uint64), gen.randint(0, self._mersenne_prime, dtype=np.uint64)) for _ in range(num_perm)\n",
    "        ], dtype=np.uint64).T\n",
    "\n",
    "\n",
    "\n",
    "    def update_batch(self, b):\n",
    "        #hv = np.array([self.hashfunc(_b) for _b in b], dtype=np.uint64)\n",
    "        \n",
    "        hv = np.array([self.hashfunc(_b) for _b in b], dtype=np.uint64)\n",
    "        a, b = self.permutations\n",
    "        phv = np.bitwise_and(((hv * np.tile(a, (len(hv), 1)).T).T + b) % self._mersenne_prime, self._max_hash)\n",
    "        self.hashvalues = np.vstack([phv, self.hashvalues]).min(axis=0)\n",
    "\n",
    "    def jaccard(self, other):\n",
    "        return float(np.count_nonzero(self.hashvalues==other.hashvalues)) / float(len(self.hashvalues))\n",
    "    \n",
    "    def __len__(self):\n",
    "    \n",
    "        return len(self.hashvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self):\n",
    "        self.hash_table = defaultdict(list)\n",
    "        \n",
    "    def generate_hash(self, inp_vector):\n",
    "        hashVal = 0\n",
    "        for i in inp_vector:\n",
    "            hashVal ^= fibonacci_hash_float(i) ^ hashVal\n",
    "        return hashVal\n",
    "            \n",
    "    def setitem(self, vec, label):\n",
    "        val = self.generate_hash(vec)\n",
    "        self.hash_table[val].append(label)\n",
    "        \n",
    "        \n",
    "    def getitem(self, inp_vec):\n",
    "        hash_value = self.generate_hash(inp_vec)\n",
    "        return self.hash_table.get(hash_value, [])\n",
    "    \n",
    "    def getTable(self):\n",
    "        return(self.hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, minhash_len, num_band):\n",
    "        \n",
    "        assert minhash_len % num_band == 0, \"the choosen number of band does not hold the following assertion: minhash_len % num_band == 0\"\n",
    "        self.minhash_len = minhash_len\n",
    "        self.num_band = num_band\n",
    "        self.hash_tables = list()\n",
    "        self.minhash_dict = dict()\n",
    "        for i in range(self.num_band):\n",
    "            self.hash_tables.append(HashTable())\n",
    "            \n",
    "            \n",
    "    def addMinHash(self, minhash, label):\n",
    "        self.minhash_dict[label] = minhash\n",
    "        self.create_store_band(minhash.hashvalues, label)\n",
    "            \n",
    "    def create_store_band(self, vec, label):\n",
    "        \n",
    "        row_per_band = self.minhash_len // self.num_band\n",
    "        \n",
    "        subVec = []\n",
    "        \n",
    "        for i in range(0,self.minhash_len, row_per_band):\n",
    "            subVec.append(vec[i:i+row_per_band])\n",
    "        \n",
    "\n",
    "        for band, table in zip(subVec, self.hash_tables):\n",
    "            table.setitem(band, label)\n",
    "            \n",
    "    \n",
    "    def create_band(self, vec):\n",
    "        \n",
    "        row_per_band = self.minhash_len // self.num_band\n",
    "        \n",
    "        subVec = []\n",
    "        \n",
    "        for i in range(0,self.minhash_len, row_per_band):\n",
    "            subVec.append(vec[i:i+row_per_band])\n",
    "        \n",
    "        return subVec\n",
    "    \n",
    "            \n",
    "    def query(self, minhash_query):\n",
    "        subVec_query = self.create_band(minhash_query.hashvalues)\n",
    "        match = set()\n",
    "        similarities = []\n",
    "        for table, band in zip(self.hash_tables, subVec_query):\n",
    "            \n",
    "            key = 0\n",
    "            for i in band:\n",
    "                key ^= fibonacci_hash_float(i) ^ key\n",
    "                \n",
    "            if(table.hash_table.get(key, \"NA\") != \"NA\"):\n",
    "                match.update(tuple(table.hash_table.get(key)))\n",
    "                break\n",
    "                \n",
    "        for m in match:\n",
    "            \n",
    "            similarities.append((self.minhash_dict[m].jaccard(minhash_query), m))\n",
    "                \n",
    "        return similarities\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def info(self):\n",
    "        print(\"Numero di tabelle: \" + str(self.num_tables))\n",
    "        print(\"Elementi per tabella: \" + str(len(self.hash_tables[0].hash_table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the fisrt query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peaks = get_all_peaks(songs, duration=30)\n",
    "#save_object(peaks, \"./data/fingerprints/peaks_dur_30_hop_0.plk\")\n",
    "#fings = read_object(\"./data/figs.plk\")\n",
    "minhashes = []\n",
    "\n",
    "for fing, song in zip(peaks,songs):\n",
    "    m = MinHash(num_perm=30)\n",
    "    m.update_batch(fing)\n",
    "    minhashes.append((m,song))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mq = MinHash(num_perm=30)\n",
    "\n",
    "mq.update_batch(getPeaks(\"./data/queries/track1.wav\", duration=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for h in minhashes:\n",
    "    out.append((h[0].jaccard(mq), h[1]))\n",
    "\n",
    "[ i for i in sorted(out, reverse=True) if i[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = LSH(minhash_len=30, num_band=10)\n",
    "\n",
    "for i in minhashes:\n",
    "    lsh.addMinHash(i[0], i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/steely_dan/Aja/05-Home_At_Last.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/fleetwood_mac/Tusk/02-The_Ledge.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/fleetwood_mac/Tusk/04-Save_Me_a_Place.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/creedence_clearwater_revival/Bayou_Country/01-Born_On_The_Bayou.wav')),\n",
       " (0.1,\n",
       "  PosixPath('data/mp3s-32k/beatles/The_White_Album_Disc_1/13-Rocky_Raccoon.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/suzanne_vega/Solitude_Standing/08-Language.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/dave_matthews_band/Stand_Up/08-Out_Of_My_Hands.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/green_day/Dookie/03-Chump.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/creedence_clearwater_revival/Green_River/09-The_Night_Time_Is_The_Right_Time.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/dave_matthews_band/Before_These_Crowded_Streets/02-Rapunzel.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/queen/Sheer_Heart_Attack/03-Tenement_Funster.wav')),\n",
       " (0.1, PosixPath('data/mp3s-32k/roxette/Crash_Boom_Bang_/06-Vulnerable.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/steely_dan/Pretzel_Logic/11-Monkey_in_Your_Soul.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/radiohead/Pablo_Honey/02-Creep.wav')),\n",
       " (0.06666666666666667,\n",
       "  PosixPath('data/mp3s-32k/beatles/Revolver/01-Taxman.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/fleetwood_mac/Rumours/01-Second_Hand_News.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/cure/Kiss_Me_Kiss_Me_Kiss_Me/13-Icing_Sugar.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/queen/The_Game/07-Don_t_Try_Suicide.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/led_zeppelin/Led_Zeppelin_II/02-What_Is_And_What_Should_Never.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/roxette/Joyride/14-perfect_day.wav')),\n",
       " (0.1,\n",
       "  PosixPath('data/mp3s-32k/garth_brooks/The_Chase/05-Walking_After_Midnight.wav')),\n",
       " (0.03333333333333333,\n",
       "  PosixPath('data/mp3s-32k/suzanne_vega/Solitude_Standing/06-Solitude_Standing.wav'))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.query(mq)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f1 = make_fingerprints(\"./data/mp3s-32k/aerosmith/Aerosmith/01-Make_It.wav\", 10)\n",
    "f2 = make_fingerprints(\"./data/mp3s-32k/aerosmith/Aerosmith/01-Make_It.wav\", 30)\n",
    "f3 = make_fingerprints(\"./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav\", 30)\n",
    "\n",
    "m1 = MinHash(num_perm=30)\n",
    "m2 = MinHash(num_perm=30)\n",
    "m3 = MinHash(num_perm=30)\n",
    "\n",
    "m1.update_batch(f1)\n",
    "\n",
    "m2.update_batch(f2)\n",
    "\n",
    "m3.update_batch(f3)\n",
    "\n",
    "print(m1.jaccard(m2), \"Make it\")\n",
    "print(m1.jaccard(m3), \"Dream_on\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lsh = LSH(minhash_len=300, num_band=15)\n",
    "\n",
    "lsh.addMinHash(m2, \"Make it\")\n",
    "lsh.addMinHash(m3, \"Dream_on\")\n",
    "\n",
    "lsh.query(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4641588833612779"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 10\n",
    "r = 30 /b\n",
    "\n",
    "t = (1/b)**(1/r)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, o1 = getPeaks(\"./data/mp3s-32k/aerosmith/Aerosmith/03-Dream_On.wav\", 50)\n",
    "p2, o2 = getPeaks(\"./data/mp3s-32k/beatles/A_Hard_Day_s_Night/01-A_Hard_Day_s_Night.wav\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1: 114     p2: 88\n",
      "o1: 2154   o2: 2154\n"
     ]
    }
   ],
   "source": [
    "print(\"p1: \" + str(len(p1)) + \"     p2: \" + str(len(p2)) + \"\\no1: \" + str(len(o1)) + \"   o2: \" + str(len(o2)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cab321cb1acdda0c363d7de36f5defdacb4b1bdc03056ebbf5164ad5dbb0ce6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
